{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_class=v=11   h=n_hidden=128   b=1   max_len=m=5\\ndkfjd \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "见书本attention章图解\n",
    "attention中分为三大快     encode,decode\n",
    "input = [['ich mochte ein bier P'],[].....]   (m,b,v)\n",
    "output =[['S i want a beer'], [],[]......]   (m,b,v)\n",
    "target = [['i want a beer E'],[],[]......]   (m,b)\n",
    "\n",
    "随机初始化最开始的hidden (1,b,h)\n",
    "input和hidden运行RNN操作\n",
    "enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)    #self.enc_cell( (m,b,v),(1,b,h) )\n",
    "# enc_outputs :(m,b,h)   enc_hidden: (1,b,h)\n",
    "\n",
    "enc_hidden作为新的hidden ， 和output每一层进行RNN操作（迭代m次）：\n",
    "for i in range(m): \n",
    "            # 得到dec_output:(1,b,h) 和新的hidden：(1,b,h)\n",
    "            dec_output, hidden = self.dec_cell( dec_inputs[i], hidden)      # self.dec_cell(   (b,v), ( 1,b,h )  )\n",
    "            \n",
    "            # 用dec_output:(b,h)和enc_output(m,b,h)中的每一层(b,h)内积和操作得到m层(1,b),即(m,1,b),然后softmax操作得attention=(m,1,b)  \n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)   #self.get_att_weight(  (1,b,h), (m,b,h) )      \n",
    "            \n",
    "            #attention：(b,m,1)和enc_outputs :(b,m,h) 运行bmm（batch  matrix multip)操作得到context=(b,1,h)  \n",
    "            #                                          <=============>  等效于每一层enc_output和其attention的乘积，然后相加\n",
    "            context = attn_weights.bmm(enc_outputs)\n",
    "            \n",
    "            #context：(b,1,h) 和这一层的dec_output:(1,b,h)运行concat操作得到(b,2h)\n",
    "            #(v,2h)*(b,2h) =(v,b)\n",
    "output的每一层/每一次迭代得到一个(v,b)，m次后得到(v,b,m)\n",
    "(v,b,m)和target:(m,b)运行交叉熵得到loss，反向传播\n",
    "\n",
    "\n",
    "test操作：\n",
    "input = ['ich mochte ein bier P']      \n",
    "output =['S P P P P P']\n",
    "求target是否等于['i want a beer E'],\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word_list= ['i', 'beer', 'E', 'a', 'ein', 'S', 'P', 'want', 'ich', 'bier', 'mochte']\n number_dict= {0: 'i', 1: 'beer', 2: 'E', 3: 'a', 4: 'ein', 5: 'S', 6: 'P', 7: 'want', 8: 'ich', 9: 'bier', 10: 'mochte'}\n n_class= 11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "number_dict = {i: w for i, w in enumerate(word_list)}\n",
    "n_class = len(word_dict)  # vocab list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(' word_list=',word_list)\n",
    "print(' number_dict=',number_dict)\n",
    "print(' n_class=',n_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(sentences):\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]      #(b,m,v)= (1,5,11)\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]      #(b,m,v)= (1,5,11)\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]                       #(b,m)=(1,5)\n",
    "    # make tensor\n",
    "    return Variable(torch.Tensor(input_batch)), Variable(torch.Tensor(output_batch)), Variable(torch.LongTensor(target_batch))\n",
    "\n",
    "input_batch, output_batch, target_batch = make_batch(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)  #(v,h)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)  #(v,h)\n",
    " \n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)   #(h,h)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class) #(2h,v)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):         #model(  (b,m,v),(1,b,h),(b,m,v)   )\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: (m,b,v) \n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: (m,b,v) \n",
    "\n",
    "        # enc_outputs : [m, b, num_directions(=1) * h]            =(m,b,h)=(5,1,h)           matrix F\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), b, h]=(1,b,h)\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)  #self.enc_cell( (m,b,v),(1,b,h) )\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden #(1,b,h)=(1,1,h)\n",
    "        # dec_inputs.size()   =  torch.Size([5, 1, 11]) =(m,b,v)\n",
    "        n_step = len(dec_inputs)            #n_step=m=5\n",
    "\n",
    "        model = Variable(torch.empty([n_step, 1, n_class]))      #(m,b,v)=(5,1,v)\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [m(=1), b(=1), num_directions(=1) * h] =(m,b,h) =(1,1,h)\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), b(=1), h] = (1,b,h) = (1,1,h)\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)       # self.dec_cell(   (b,v), ( 1,b,h )  )\n",
    "            \n",
    "            # attn_weights : [b,1,m]=(1,1,m)\n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)   #self.get_att_weight(  (1,b,h), (5,1,h)          )      \n",
    "                # print(attn_weights.squeeze())                            #tensor([ 0.1914,  0.2034,  0.2043,  0.1994,  0.2016])\n",
    "                # print(attn_weights.squeeze().data.numpy())               #[0.19141854 0.20338222 0.20427436 0.19936943 0.20155545]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [b,1,m] x [b,m,h] =(b,1,h)=(1,1,m)x (1,m,h) = (1,1,h)\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
    "            dec_output = dec_output.squeeze(0)      # (1,b,h) ===>(b,h)\n",
    "            context = context.squeeze(1)            # (b,1,h)===>(b,h)\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))  #(2h,v) *(2h,b) =(v,b)\n",
    "        # model.size() =(m,b,v)= torch.Size([5, 1, 11])\n",
    "        # model.transpose(0,1).squeeze(0).size()       #(m,b,v)=====>(b,m,v)====>(b*m,v)\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
    "\n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        n_step = len(enc_outputs)\n",
    "        attn_scores = Variable(torch.zeros(n_step))  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs=dec_output=  [b, num_directions(=1) * h]=(h,b)\n",
    "        score = self.attn(enc_output)  # score : (h,b)*(h,b)= (h,b)\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value# Parameter\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software_installed_cs\\Anaconda3\\envs\\pytorch0.4\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\nC:\\software_installed_cs\\Anaconda3\\envs\\pytorch0.4\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0800 cost = 0.000161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200 cost = 0.000079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600 cost = 0.000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000 cost = 0.000030\n"
     ]
    }
   ],
   "source": [
    "# Parameter\n",
    "n_hidden = 128\n",
    "\n",
    "# hidden : [num_layers(=1) * num_directions(=1), b, h]=(1,b,h)\n",
    "hidden = Variable(torch.zeros(1, 1, n_hidden))\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)       #model(  (b,m,v),(1,b,h),(b,m,v)   )     output:(b*m,v)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))     # target_batch:(b,m)=>(b*m)\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ich mochte ein bier P =========> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software_installed_cs\\Anaconda3\\envs\\pytorch0.4\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAE2CAYAAADyN1APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQ8ElEQVR4nO3decxldX3H8fcHZhjC1hTFsClUUCupSnAArQtjoB1aY9Io0WihiomDW0XFJa1FbayhuESsKHUicTTBRo3GBVHUygSNIAyWqh0toCIM6yD7Ngz47R/njL1cfzPM88xzn3N55v1KbmbuOefe8/s9d573nGWWVBWSpIfbYegBSNI0Mo6S1GAcJanBOEpSg3GUpAbjKEkNxnFEklVJzt2K7Q5MUkmWzse4htDP77ihx7GtHk3zSLI6yZmzXa+5tWjoAUyZk4EMPYhHgyQHAr8GDq+qNcOOZov2AW4behBz5MXAxqEHMQlJVgGv7J8+CFwLfBl4T1XdM8SYjOOIqrpj6DFoblXVjUOPYa5U1a3b+h5JFlfVtAb2u8AJwGLgecCngF2B1w0xGE+rR4yeVqdzSpIrk2xIsi7JaWMvOSDJd5Lcm2Rtkr+Y0LhWJzkryYeT3JpkfZKTkyxJ8vEktye5JskJI695WpLvJrmvf82qJH809r6vTPLTfn439b97j9ozyReT3JPkV0mOH1n36/7HS/tT19Uj73ti//W4P8kVSd6SZCK/1vrP6R1JftnP9aej4xw9rR65HPKS+fjcZmlRko8mua1/fHDT1278tDrJTklO739t3pPk0iTLR9Yv6+f710kuSfIAsLyxz2mxoapurKprq+pzwDnA3ww2mqry0T+AVcC5/c9PA24HXg0cDDwbeH2/7kCggF8ALwKeBHwG+C2w2wTGtRq4E3hvv69T+v1/k+5SwMHA+4ANwL7ALsB1wFeApwFHAVcAXxp5z5OA+4G3Ak8Bngm8fWR9AeuA4/v3Pw14ADigX394v81yYG9gz375a4AbgOOAP+m/PjcCb5zQZ/Z+4H+BY/v9vQK4B3jhyDyOG+Jzm+XnfBfwMeBPgZcCdwBvHVl/5sj25wAXA88Hngi8sf+MntGvX9bP96fAX/bb7DX0PB/pe29k2b8Btww2pqG/KNP02PQBAbv14XjtZrbb9E120siy/fplz53AuFYDF408D7Ae+NrIssX9N8ZxfaDuAHYfWb/pG+Xg/vk64F+3sM8CTht5vgi4Fzh+7GuwdOx11wAnjC17M7B2Al+XXYH7gOeNLT8DOG9kHuNxnJfPbZaf8xVARpb9E7BuZP2Z/c8PAn4HPGHsPb4CfGLsM3/J0HPbirk/LI7AEcAtwOeHGpPXHNsOAZYA//kI2/1k5OfX9z8+biIjGtlXVVWSm+mOCDYt25jktn7/BwM/qaq7Rl7/Q7pvpkOS3EkXha2eX1U9mGQ9W5hfkr2AxwOfTHLWyKpFTOZG1yHAzsC3koz+CyqLgau38Lr5/Nxm6uLq69C7CHhfkj3GtjuM7mu6NnnYl3YJ8L2xbaf5htmoY5PcTffrZTHwVeDvhxqMcWzb2m/k31/Y7oMFk7uOO34RvTazbAe68W/un1sqZjG/sfffnE3rXksX40nbtL8X0R2xjtrSTYf5/NwmZQe6z+Nw/nCu9409H+Ru7yxcCKygm8/1NfCNI+PYtpbu+t3RwJUDj2U21gKvTrL7yNHjn9N9Q/28qm5Kch3d/L4zy3080P+446YFI+97UFV9dpbvOxObPqcDqmr8aOnR6sgkGTl6fBZdKO4cO0L8L7rf5Pauqgvme5ATcm9VXTX0IDYxjg1VdVeSjwKnJdlA9zvaY4BnVtVZW371VDgH+Gfgs0neDfwx8EngyyO/+N4PfCTJTcA36G7iHF1VH97KfdxMd4SyPMnVwP3V/VGo9wIfS3I7cB7d6dFhwH5VNX63f5v0n9OHgA+lK8eFdNeLnwX8rqpWzuX+5sm+wBlJPkF3M+3twL+Mb1RVVyQ5B1iV5BTgx8CedNcZf1VVX56/IS9MxnHz/oHuDw+fCuwP3ATMx9HQNquqe/s/0nEGcAndzaWv0t3Z3rTNWf0f7TgFOB24lS5mW7uPB5O8CXg38B7g+8CyqvpUknvovqlPowvo/wCT+psdp9J9Nm8DzqK7q3858IEJ7W/SzqE7Gv8R3Wnz2cBHNrPticC76Oa6P91neAmwUI4kB5WHX/uVJMGj7yK0JM0L4yhJDcZRkhqMoyQ1GEdJajCOktRgHGcoyYqhxzAJC3VesHDn5rwmyzjO3FR8cBOwUOcFC3duzmuCjKMkNSyIvyGzU5bUzuw6L/vayAYWs2Re9jWfFuq8YOHObb7n9eSn3zsv+1n/24fY6zE7PvKGc+Syn2y4par2Gl++IP5u9c7sypE5euhhSAva+edfPvQQJmLHfa76TWu5p9WS1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpIapjmOSVUnOHXockrY/0/6/D54MZOhBSNr+THUcq+qOoccgafvkabUkNUx1HCVpKFN9Wr0lSVYAKwB2ZpeBRyNpoXnUHjlW1cqqWlpVSxezZOjhSFpgHrVxlKRJMo6S1GAcJanBOEpSw1Tfra6qVw09BknbJ48cJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpAbjKEkNxlGSGoyjJDUYR0lqMI6S1GAcJanBOEpSg3GUpIapjGOS1UnOHHockrZfUxlHSRraI8YxyV8luSvJov75k5JUkrNGtnl/ku8k2THJ2Ul+neS+JFcmeUeSHUa2XZXk3CQnJ7kuyW1JPp1kl03rgaOAN/T7qSQHzvG8JWmLFm3FNt8HdgaWAhcDy4BbgBeMbLMMOI8uttcBLwXWA0cAK4HfAmePbP884AbgGODxwBeAK4DTgJOBJwO/AP6x3379DOclSdvkEY8cq+pu4Mf8fwyXAWcCByTZpz/iOxxYXVUbq+rdVXVpVV1dVV8A/h14+djb3gm8rqp+XlXfBr4IHN3v7w7gAeDeqrqxfzw0Pq4kK5KsSbJmIxtmM3dJ2qytvea4mi6K0J3yfhO4pF/2HGBj/5wkr+2jtT7J3cBbgCeMvd/aqnpw5Pn1wONmMvCqWllVS6tq6WKWzOSlkvSIZhLH5yQ5BNgduKxf9gK6QP6wqjYmeRlwBrAKWA4cCnwC2Gns/TaOPa8ZjEWSJm5rrjlCd91xCfAO4AdV9VCS1XTXE2+mu94I8FzgR1X1+z+Gk+SgWYzrAWDHWbxOkubEVh2tjVx3PB64oF98Ed3NlCPpjiKhu6lyWH+H+0lJTqU7DZ+pq4EjkhyY5LGjd7slaT7MJDoX0B3NrQaoqvvp7l5voL/eCHyS7s7z54BLgQOBD89iXB+iO3pcS3enevyapSRNVKpq6DFssz2yZx2Zo4cehrSgnX/95UMPYSJ23Oeqy6pq6fhyT1clqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ1b+/9WS3Nqof5nTcv3PXToIUzMwp3bVc2lHjlKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUsNUxTHJsUm+n+S2JLcmOT/JU4cel6Ttz1TFEdgVOAM4AlgG3AF8PclO4xsmWZFkTZI1G9kwv6OUtOAtGnoAo6rqS6PPk5wI3EkXyx+MbbsSWAmwR/as+RqjpO3DVB05JjkoyeeS/DLJncBNdGN8wsBDk7SdmaojR+DrwHXASf2PDwJrgT84rZakSZqaOCZ5DPBU4A1VdUG/7DCmaIySth/TFJ7bgFuA1yS5FtgP+CDd0aMkzaupueZYVb8DXgY8HfgZ8HHgVPBWtKT5N01HjlTV94A/G1u82xBjkbR9m5ojR0maJsZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1TNX/IaOHO//6y4cewsQs3/fQoYcgbZFHjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIaZhTHJKuTnDmpwUjStPDIUZIapj6OSXYaegyStj+zieOiJB9Nclv/+GCSHaALWZLTk6xLck+SS5MsH31xkkOSfCPJXUluTvIfSfYeWb8qyblJ3plkHbBu26YoSTM3mzj+bf+6ZwMnASuAN/frPg0cBbwCeBrwGeDrSZ4BkGQf4ELgZ8ARwDHAbsDXNgW2dxTwdOBY4OhZjFGStsmiWbzmBuBNVVXAL5I8GXhrkq8CLwcOrKpr+m3PTHIMXURfD7wO+O+qeuemN0vyd8CtwFLgkn7x/cCrq2rD5gaRZAVdmNmZXWYxDUnavNkcOV7ch3GTi4D9gOcCAdYmuXvTA3ghcFC/7TOB54+tv7Zfd9DIe/5sS2EEqKqVVbW0qpYuZskspiFJmzebI8ctKeBwYOPY8vv6H3cAvgG8rfHam0Z+fs8cj0uSZmQ2cTwySUaOHp8FXE93BBlg76q6YDOv/THwUuA3VTUeUEmaGrM5rd4XOCPJU5IcB7wd+EhVXQGcA6xKclySJyZZmuRtSV7cv/bjwB8Bn09yZL/NMUlWJtl9TmYkSXNgNkeO5wA7Aj+iO40+G/hIv+5E4F3AB4D96W60XAJcAFBV1yd5DnAa8C1gZ+Aa4NvAFq8xStJ8mlEcq2rZyNM3NtZvBN7bPzb3HlcCx21h/atmMiZJmoSp/xsykjQE4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhqMoyQ1GEdJajCOktRgHCWpwThKUoNxlKQG4yhJDcZRkhrm+v+t1hxavu+hQw9BM5UMPYKJOW/dZUMPYSJ22re93CNHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIapiaOSVYlqcbj4qHHJmn7s2joAYz5LnDC2LIHhhiIpO3btMVxQ1XdOPQgJGlqTqslaZpMWxyPTXL32OP01oZJViRZk2TNRjbM9zglLXDTdlp9IbBibNntrQ2raiWwEmCP7FkTHpek7cy0xfHeqrpq6EFI0rSdVkvSVJi2I8clSfYeW/ZQVa0fZDSStlvTFsdjgBvGll0H7D/AWCRtx6bmtLqqXlVVaTwMo6R5NzVxlKRpYhwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkBuMoSQ3GUZIajKMkNRhHSWowjpLUYBwlqcE4SlKDcZSkhlTV0GPYZknWA7+Zp909FrhlnvY1nxbqvGDhzs15zY0Dqmqv8YULIo7zKcmaqlo69Djm2kKdFyzcuTmvyfK0WpIajKMkNRjHmVs59AAmZKHOCxbu3JzXBHnNUZIaPHKUpAbjKEkNxlGSGoyjJDUYR0lq+D+1LXXWFnrYGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "# sentences = ['ich mochte ein bier P', 'S P P P P']\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]  #(b,m,v)=(1,5,v)\n",
    "test_batch = Variable(torch.Tensor(test_batch))\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '=========>', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "\n",
    "\n",
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
